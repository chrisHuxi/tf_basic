{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from PIL import Image\n",
      "import random\n",
      "import numpy as np\n",
      "import os\n",
      "import tensorflow as tf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
        "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#======================================Part1.\u6570\u636e\u51c6\u5907==================================#\n",
      "####\u5c06csv\u6587\u4ef6\u4e2d\u7684\u6570\u636e\u63d0\u53d6\u5230list\u4e2d\uff0c\u5206\u522b\u653e\u5728Label\uff081\u7ef4\uff09\u548cFeature_Vector\uff082\u7ef4\uff09\u4e2d####\n",
      "def perpare_data(): \n",
      "\tcsvfile = file( os.path.dirname(os.getcwd()) + '/data/train.csv', 'rb')\n",
      "\tFeature_Vectors = []\n",
      "\tLabels = []\n",
      "\ti = 1\n",
      "\treader = csv.reader(csvfile)\n",
      "\tfor line in reader:\n",
      "\t\tif i == 1:\n",
      "\t\t\ti = i + 1\n",
      "\t\t\tcontinue\n",
      "\t\tLabels.extend(line[0])\n",
      "\t\tFeature_Number_List = ConvertPixls2Float(List_StringTONumber(line[1:len(line)]))\n",
      "\t\tFeature_Vectors.append(Feature_Number_List)\n",
      "\t\t#Feature_Vectors.append(line[1:len(line)])\n",
      "\tLabels =List_StringTONumber(Labels)\n",
      "\tcsvfile.close()\n",
      "\t#print Feature_Vectors[0]\n",
      "\timages = ListToImage(Feature_Vectors)\n",
      "\t#print images[:][:][0]\n",
      "\treturn images,np.array(Labels)\n",
      "\n",
      "\n",
      "####\u5c06\u5b57\u7b26\u5217\u8868lists=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\u8f6c\u5316\u4e3a\u6570\u5b57\u5217\u8868####\n",
      "def List_StringTONumber(lists):  \n",
      "\tlists= map(int, lists)\n",
      "\ttemp_lists = []\n",
      "\tfor i in lists:\n",
      "\t\ttemp_lists.append(i)\n",
      "\treturn temp_lists\n",
      "\t\n",
      "####\u5c060~255\u7684pixls\u503c\u8f6c\u6210-1.0~1.0\u7684float\u7c7b\u578b\u6570####\n",
      "def ConvertPixls2Float(lists):\n",
      "\tFloatNumber_list = []\n",
      "\tfor everyeum in lists:\n",
      "\t\tFloatNumber = (everyeum/255.0)*2 - 1.0\n",
      "\t\tFloatNumber_list.append(FloatNumber)\n",
      "\treturn FloatNumber_list\n",
      "\t\n",
      "####\u5c0642000*784\u7684\u56fe\u50cf\u8f6c\u5316\u4e3a28*28*42000\u7684array\u7c7b\u578b\n",
      "def ListToImage(featureList):\n",
      "\tfeatureArray = np.array(featureList)\n",
      "\t#print size(featureArray,0)\n",
      "\t#print size(featureArray,1)\n",
      "\t\n",
      "\timages = np.zeros([42000,28,28])\t#28*28*42000\n",
      "\tfor i in range(0,np.size(featureArray,0)):\t\t\n",
      "\t\timages[i,:,:] = (featureArray[i]).reshape((np.sqrt(np.size(featureArray,1)),np.sqrt(np.size(featureArray,1))))\n",
      "\treturn images\n",
      "#========================================================================================#\t\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images,labels = perpare_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:49: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def drawImage(images,testLabels):\n",
      "    print (\"**************for test*************\")\n",
      "    x=280\n",
      "    y=280\n",
      "\t#\u6839\u636e\u50cf\u7d20\u70b9\u753b\u51fa\u56fe\u50cf,\u6765\u5224\u65ad\u52a0\u8f7d\u6570\u636e\u662f\u5426\u6b63\u786e\n",
      "    c = Image.new(\"L\",(x,y))\n",
      "    for m in range(0,10):\n",
      "        for n in range(0,10):\n",
      "            for i in range (0,28):\n",
      "                for j in range (0,28):\n",
      "                    c.putpixel([j+m*28,i+n*28],((images[m+n*10][i][j]+1)*255/2))\n",
      "    c.show()\n",
      "    c.save('drawImage.png')\n",
      "    print (\"*************test end**************\")\n",
      "\n",
      "drawImage(images,labels)\n",
      "print(images.shape)\n",
      "print(labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "**************for test*************\n",
        "*************test end**************"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(42000, 28, 28)\n",
        "(42000,)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image_size = 28\n",
      "num_labels = 10\n",
      "num_channels = 1\n",
      "\n",
      "def reformat(images,labels):\n",
      "    image_num = images.shape[0]\n",
      "    train_dataset_num = int(image_num*0.8)\n",
      "    train_dataset = images[0:train_dataset_num,:,:].reshape(train_dataset_num, image_size, image_size, num_channels).astype(np.float32)\n",
      "    train_labels = (np.arange(num_labels) == labels[0:train_dataset_num,None]).astype(np.float32)\n",
      "    \n",
      "    valid_dataset_num = int(image_num*0.1)\n",
      "    valid_dataset = images[train_dataset_num:(train_dataset_num+valid_dataset_num-1),:,:].reshape(-1, image_size, image_size, num_channels).astype(np.float32)\n",
      "    valid_labels = (np.arange(num_labels) == labels[train_dataset_num:(train_dataset_num+valid_dataset_num-1),None]).astype(np.float32)\n",
      "    \n",
      "    test_dataset = images[(train_dataset_num+valid_dataset_num):,:,:].reshape(-1, image_size, image_size, num_channels).astype(np.float32)\n",
      "    test_labels = (np.arange(num_labels) == labels[(train_dataset_num+valid_dataset_num):,None]).astype(np.float32)\n",
      "    \n",
      "    return train_dataset, train_labels,valid_dataset, valid_labels,test_dataset, test_labels\n",
      "\n",
      "train_dataset, train_labels,valid_dataset, valid_labels,test_dataset, test_labels = reformat(images,labels)\n",
      "print('Training set', train_dataset.shape, train_labels.shape)\n",
      "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
      "print('Test set', test_dataset.shape, test_labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Training set', (33600, 28, 28, 1), (33600, 10))\n",
        "('Validation set', (4199, 28, 28, 1), (4199, 10))\n",
        "('Test set', (4200, 28, 28, 1), (4200, 10))\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def accuracy(predictions, labels):\n",
      "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
      "          / predictions.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "batch_size = 128\n",
      "patch_size = 5\n",
      "depth = 16\n",
      "num_hidden = 1024\n",
      "num_hidden2 = 32\n",
      "\n",
      "graph = tf.Graph()\n",
      "\n",
      "with graph.as_default():\n",
      "\n",
      "  # Input data.\n",
      "  tf_train_dataset = tf.placeholder(\n",
      "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
      "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
      "  tf_valid_dataset = tf.constant(valid_dataset)\n",
      "  tf_test_dataset = tf.constant(test_dataset)\n",
      "  \n",
      "  # Variables.\n",
      "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
      "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
      "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
      "  '''  '''\n",
      "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
      "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
      "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
      "\n",
      "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
      "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
      "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
      "    \n",
      "  layer4_weights = tf.Variable(tf.truncated_normal(\n",
      "      [num_hidden, num_hidden2], stddev=0.1))\n",
      "  layer4_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden2]))\n",
      "    \n",
      "  layer5_weights = tf.Variable(tf.truncated_normal(\n",
      "      [num_hidden2, num_labels], stddev=0.1))\n",
      "  layer5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
      "    \n",
      "  \n",
      "  \n",
      "  # Model.\n",
      "  def model(data):\n",
      "    conv = tf.nn.conv2d(data, layer1_weights, [1, 1, 1, 1], padding='SAME',use_cudnn_on_gpu=True)\n",
      "    hidden = tf.nn.relu(conv + layer1_biases)\n",
      "    pooling = tf.nn.max_pool(hidden, [ 1,2,2,1 ] , [1, 2, 2, 1], padding='SAME')\n",
      "    \n",
      "    conv =  tf.nn.conv2d(pooling, layer2_weights, [1, 1, 1, 1], padding='SAME',use_cudnn_on_gpu=True)\n",
      "    hidden = tf.nn.relu(conv + layer2_biases)\n",
      "    pooling = tf.nn.max_pool(hidden, [ 1,2,2,1 ] , [1, 2, 2, 1], padding='SAME')\n",
      " \n",
      "    shape = pooling.get_shape().as_list()\n",
      "    reshape = tf.reshape(pooling, [shape[0], shape[1] * shape[2] * shape[3]])\n",
      "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
      "    \n",
      "    hidden2 = tf.nn.relu(tf.matmul(hidden, layer4_weights) + layer4_biases)\n",
      "    \n",
      "    return tf.matmul(hidden2, layer5_weights) + layer5_biases\n",
      "  \n",
      "  # Training computation.\n",
      "  logits = model(tf_train_dataset)\n",
      "  loss = tf.reduce_mean(\n",
      "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
      "    \n",
      "  # Optimizer.\n",
      "  global_step = tf.Variable(0)  # count the number of steps taken.\n",
      "  learning_rate = tf.train.exponential_decay(0.05, global_step, num_steps, 0.96)\n",
      "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
      "  \n",
      "  # Predictions for the training, validation, and test data.\n",
      "  train_prediction = tf.nn.softmax(logits)\n",
      "  valid_prediction = tf.nn.softmax(model(tf_valid_dataset))\n",
      "  test_prediction = tf.nn.softmax(model(tf_test_dataset))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_steps = 2001\n",
      "\n",
      "with tf.Session(graph=graph) as session:\n",
      "  tf.initialize_all_variables().run()\n",
      "  print('Initialized')\n",
      "  for step in range(num_steps):\n",
      "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
      "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
      "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
      "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
      "    _, l, predictions = session.run(\n",
      "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
      "    if (step % 50 == 0):\n",
      "      print('Minibatch loss at step %d: %f' % (step, l))\n",
      "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
      "      print('Validation accuracy: %.1f%%' % accuracy(\n",
      "        valid_prediction.eval(), valid_labels))\n",
      "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialized\n",
        "Minibatch loss at step 0: 3.696386"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 10.2%\n",
        "Validation accuracy: 8.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 50: 1.258570"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 61.7%\n",
        "Validation accuracy: 60.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 100: 0.578627"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 78.9%\n",
        "Validation accuracy: 72.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 150: 0.197035"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 96.1%\n",
        "Validation accuracy: 93.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 200: 0.301197"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.8%\n",
        "Validation accuracy: 94.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 250: 0.149907"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 93.8%\n",
        "Validation accuracy: 95.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 300: 0.186207"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 93.0%\n",
        "Validation accuracy: 95.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 350: 0.284982"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 92.2%\n",
        "Validation accuracy: 95.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 400: 0.088321"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 96.9%\n",
        "Validation accuracy: 96.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 450: 0.210447"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 91.4%\n",
        "Validation accuracy: 95.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 500: 0.093234"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 97.7%\n",
        "Validation accuracy: 97.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 550: 0.225220"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 93.0%\n",
        "Validation accuracy: 94.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 600: 0.061497"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 98.4%\n",
        "Validation accuracy: 97.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 650: 0.179219"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 96.9%\n",
        "Validation accuracy: 97.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 700: 0.072917"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 97.7%\n",
        "Validation accuracy: 97.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 750: 0.123064"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 95.3%\n",
        "Validation accuracy: 95.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 800: 0.011180"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 100.0%\n",
        "Validation accuracy: 97.5%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 850: 0.148128"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 96.1%\n",
        "Validation accuracy: 97.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 900: 0.007843"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 100.0%\n",
        "Validation accuracy: 97.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 950: 0.050385"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 97.7%\n",
        "Validation accuracy: 97.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1000: 0.062369"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 96.9%\n",
        "Validation accuracy: 97.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1050: 0.049191"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 98.4%\n",
        "Validation accuracy: 97.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1100: 0.051708"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 97.7%\n",
        "Validation accuracy: 98.1%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1150: 0.099800"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 98.4%\n",
        "Validation accuracy: 97.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1200: 0.043321"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 97.7%\n",
        "Validation accuracy: 98.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1250: 0.054947"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 97.7%\n",
        "Validation accuracy: 97.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1300: 0.068093"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 96.9%\n",
        "Validation accuracy: 97.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1350: 0.061776"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 96.9%\n",
        "Validation accuracy: 97.8%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1400: 0.061921"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 97.7%\n",
        "Validation accuracy: 98.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1450: 0.129370"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 95.3%\n",
        "Validation accuracy: 97.7%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1500: 0.050544"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 98.4%\n",
        "Validation accuracy: 97.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1550: 0.097162"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 96.9%\n",
        "Validation accuracy: 97.4%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1600: 0.038991"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 98.4%\n",
        "Validation accuracy: 98.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1650: 0.012664"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 100.0%\n",
        "Validation accuracy: 98.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1700: 0.019521"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 100.0%\n",
        "Validation accuracy: 98.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1750: 0.085440"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 97.7%\n",
        "Validation accuracy: 97.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1800: 0.016058"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 99.2%\n",
        "Validation accuracy: 97.9%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1850: 0.065203"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 96.9%\n",
        "Validation accuracy: 98.0%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1900: 0.045513"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 97.7%\n",
        "Validation accuracy: 98.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 1950: 0.005522"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 100.0%\n",
        "Validation accuracy: 98.3%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch loss at step 2000: 0.035054"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 99.2%\n",
        "Validation accuracy: 98.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Test accuracy: 98.2%"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}