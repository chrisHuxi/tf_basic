{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv\n",
      "from PIL import Image\n",
      "import random\n",
      "import numpy as np\n",
      "import os\n",
      "import tensorflow as tf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
        "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#======================================Part1.\u6570\u636e\u51c6\u5907==================================#\n",
      "####\u5c06csv\u6587\u4ef6\u4e2d\u7684\u6570\u636e\u63d0\u53d6\u5230list\u4e2d\uff0c\u5206\u522b\u653e\u5728Label\uff081\u7ef4\uff09\u548cFeature_Vector\uff082\u7ef4\uff09\u4e2d####\n",
      "def perpare_data(): \n",
      "\tcsvfile = file( os.path.dirname(os.getcwd()) + '/data/train.csv', 'rb')\n",
      "\tFeature_Vectors = []\n",
      "\tLabels = []\n",
      "\ti = 1\n",
      "\treader = csv.reader(csvfile)\n",
      "\tfor line in reader:\n",
      "\t\tif i == 1:\n",
      "\t\t\ti = i + 1\n",
      "\t\t\tcontinue\n",
      "\t\tLabels.extend(line[0])\n",
      "\t\tFeature_Number_List = ConvertPixls2Float(List_StringTONumber(line[1:len(line)]))\n",
      "\t\tFeature_Vectors.append(Feature_Number_List)\n",
      "\t\t#Feature_Vectors.append(line[1:len(line)])\n",
      "\tLabels =List_StringTONumber(Labels)\n",
      "\tcsvfile.close()\n",
      "\t#print Feature_Vectors[0]\n",
      "\timages = ListToImage(Feature_Vectors)\n",
      "\t#print images[:][:][0]\n",
      "\treturn images,np.array(Labels)\n",
      "\n",
      "\n",
      "####\u5c06\u5b57\u7b26\u5217\u8868lists=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\u8f6c\u5316\u4e3a\u6570\u5b57\u5217\u8868####\n",
      "def List_StringTONumber(lists):  \n",
      "\tlists= map(int, lists)\n",
      "\ttemp_lists = []\n",
      "\tfor i in lists:\n",
      "\t\ttemp_lists.append(i)\n",
      "\treturn temp_lists\n",
      "\t\n",
      "####\u5c060~255\u7684pixls\u503c\u8f6c\u6210-1.0~1.0\u7684float\u7c7b\u578b\u6570####\n",
      "def ConvertPixls2Float(lists):\n",
      "\tFloatNumber_list = []\n",
      "\tfor everyeum in lists:\n",
      "\t\tFloatNumber = (everyeum/255.0)*2 - 1.0\n",
      "\t\tFloatNumber_list.append(FloatNumber)\n",
      "\treturn FloatNumber_list\n",
      "\t\n",
      "####\u5c0642000*784\u7684\u56fe\u50cf\u8f6c\u5316\u4e3a28*28*42000\u7684array\u7c7b\u578b\n",
      "def ListToImage(featureList):\n",
      "\tfeatureArray = array(featureList)\n",
      "\t#print size(featureArray,0)\n",
      "\t#print size(featureArray,1)\n",
      "\t\n",
      "\timages = zeros([42000,28,28])\t#28*28*42000\n",
      "\tfor i in range(0,size(featureArray,0)):\t\t\n",
      "\t\timages[i,:,:] = (featureArray[i]).reshape((sqrt(size(featureArray,1)),sqrt(size(featureArray,1))))\n",
      "\treturn images\n",
      "#========================================================================================#\t\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images,labels = perpare_data()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def drawImage(images,testLabels):\n",
      "    print (\"**************for test*************\")\n",
      "    x=280\n",
      "    y=280\n",
      "\t#\u6839\u636e\u50cf\u7d20\u70b9\u753b\u51fa\u56fe\u50cf,\u6765\u5224\u65ad\u52a0\u8f7d\u6570\u636e\u662f\u5426\u6b63\u786e\n",
      "    c = Image.new(\"L\",(x,y))\n",
      "    for m in range(0,10):\n",
      "        for n in range(0,10):\n",
      "            for i in range (0,28):\n",
      "                for j in range (0,28):\n",
      "                    c.putpixel([j+m*28,i+n*28],((images[m+n*10][i][j]+1)*255/2))\n",
      "    c.show()\n",
      "    c.save('drawImage.png')\n",
      "    print (\"*************test end**************\")\n",
      "\n",
      "drawImage(images,labels)\n",
      "print(images.shape)\n",
      "print(labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "**************for test*************\n",
        "*************test end**************"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "(42000, 28, 28)\n",
        "(42000,)\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image_size = 28\n",
      "num_labels = 10\n",
      "\n",
      "def reformat(images,labels):\n",
      "    image_num = images.shape[0]\n",
      "    train_dataset_num = int(image_num*0.8)\n",
      "    train_dataset = images[0:train_dataset_num,:,:].reshape(train_dataset_num,( image_size * image_size)).astype(np.float32)\n",
      "    train_labels = (np.arange(num_labels) == labels[0:train_dataset_num,None]).astype(np.float32)\n",
      "    \n",
      "    valid_dataset_num = int(image_num*0.1)\n",
      "    valid_dataset = images[train_dataset_num:(train_dataset_num+valid_dataset_num-1),:,:].reshape(-1,( image_size * image_size)).astype(np.float32)\n",
      "    valid_labels = (np.arange(num_labels) == labels[train_dataset_num:(train_dataset_num+valid_dataset_num-1),None]).astype(np.float32)\n",
      "    \n",
      "    test_dataset = images[(train_dataset_num+valid_dataset_num):,:,:].reshape(-1,( image_size * image_size)).astype(np.float32)\n",
      "    test_labels = (np.arange(num_labels) == labels[(train_dataset_num+valid_dataset_num):,None]).astype(np.float32)\n",
      "    \n",
      "    return train_dataset, train_labels,valid_dataset, valid_labels,test_dataset, test_labels\n",
      "\n",
      "train_dataset, train_labels,valid_dataset, valid_labels,test_dataset, test_labels = reformat(images,labels)\n",
      "'''\n",
      "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
      "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
      "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
      "'''\n",
      "print('Training set', train_dataset.shape, train_labels.shape)\n",
      "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
      "print('Test set', test_dataset.shape, test_labels.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Training set', (33600, 784), (33600, 10))\n",
        "('Validation set', (4199, 784), (4199, 10))\n",
        "('Test set', (4200, 784), (4200, 10))\n"
       ]
      }
     ],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def accuracy(predictions, labels):\n",
      "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
      "          / predictions.shape[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "batch_size = 128\n",
      "\n",
      "inputNodeNum = image_size * image_size\n",
      "hiddenNodeNum = 1024\n",
      "outputnodeNum = num_labels\n",
      "\n",
      "graph = tf.Graph()\n",
      "with graph.as_default():\n",
      "\n",
      "  tf_train_dataset = tf.placeholder(tf.float32,\n",
      "                                    shape=(batch_size, image_size * image_size))\n",
      "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
      "  tf_valid_dataset = tf.constant(valid_dataset)\n",
      "  tf_test_dataset = tf.constant(test_dataset)\n",
      "  \n",
      "  # Variables.\n",
      "  weightsI2H = tf.Variable(\n",
      "    tf.truncated_normal([inputNodeNum, hiddenNodeNum]))\n",
      "  biasesI2H = tf.Variable(tf.zeros([hiddenNodeNum]))\n",
      "  \n",
      "  weightsH2O = tf.Variable(\n",
      "    tf.truncated_normal([ hiddenNodeNum,outputnodeNum ]))\n",
      "  biasesH2O = tf.Variable(tf.zeros([outputnodeNum]))\n",
      "  \n",
      "  \n",
      "  # Training computation.\n",
      "  FP_I2H =  tf.matmul(tf_train_dataset, weightsI2H) + biasesI2H\n",
      "\n",
      "  FP_H2O = tf.matmul(FP_I2H , weightsH2O) + biasesH2O\n",
      "    \n",
      "  loss = tf.reduce_mean(\n",
      "    tf.nn.softmax_cross_entropy_with_logits(FP_H2O, tf_train_labels))\n",
      "  \n",
      "  # Optimizer.\n",
      "  optimizer = tf.train.GradientDescentOptimizer(0.01).minimize(loss)\n",
      "  \n",
      "  # Predictions for the training, validation, and test data.\n",
      "  train_prediction = tf.nn.softmax(FP_H2O)\n",
      "  valid_prediction_T =  tf.matmul(tf_valid_dataset, weightsI2H) + biasesI2H\n",
      "    \n",
      "  valid_prediction =  tf.nn.softmax(tf.matmul(valid_prediction_T, weightsH2O) + biasesH2O)\n",
      "    \n",
      "  test_prediction_T = tf.matmul(tf_test_dataset, weightsI2H) + biasesI2H\n",
      "  test_prediction = tf.nn.softmax(tf.matmul(test_prediction_T, weightsH2O) + biasesH2O)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_steps = 20001\n",
      "\n",
      "with tf.Session(graph=graph) as session:\n",
      "  tf.initialize_all_variables().run()\n",
      "  print(\"Initialized\")\n",
      "  for step in range(num_steps):\n",
      "\n",
      "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
      "    # Generate a minibatch.\n",
      "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
      "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
      "\n",
      "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
      "    _, l, predictions = session.run(\n",
      "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
      "    if (step % 500 == 0):\n",
      "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
      "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
      "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
      "        valid_prediction.eval(), valid_labels))\n",
      "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Initialized\n",
        "Minibatch loss at step 0: 1007.112000\n",
        "Minibatch accuracy: 16.4%\n",
        "Validation accuracy: 14.1%\n",
        "Minibatch loss at step 500: 82.292038"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 75.0%\n",
        "Validation accuracy: 80.3%\n",
        "Minibatch loss at step 1000: 15.199842"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 90.6%\n",
        "Validation accuracy: 87.8%\n",
        "Minibatch loss at step 1500: 7.212520"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 94.5%\n",
        "Validation accuracy: 87.6%\n",
        "Minibatch loss at step 2000: 50.290787"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 79.7%\n",
        "Validation accuracy: 79.1%\n",
        "Minibatch loss at step 2500: 24.125710"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 88.3%\n",
        "Validation accuracy: 86.0%\n",
        "Minibatch loss at step 3000: 20.518110"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.8%\n",
        "Validation accuracy: 89.0%\n",
        "Minibatch loss at step 3500: 16.885353"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 85.2%\n",
        "Validation accuracy: 89.4%\n",
        "Minibatch loss at step 4000: 13.695844"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.1%\n",
        "Validation accuracy: 89.5%\n",
        "Minibatch loss at step 4500: 9.739943"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.1%\n",
        "Validation accuracy: 89.2%\n",
        "Minibatch loss at step 5000: 9.385839"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.1%\n",
        "Validation accuracy: 88.6%\n",
        "Minibatch loss at step 5500: 13.725451"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 87.5%\n",
        "Validation accuracy: 84.1%\n",
        "Minibatch loss at step 6000: 9.768855"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 88.3%\n",
        "Validation accuracy: 90.5%\n",
        "Minibatch loss at step 6500: 13.473988"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.1%\n",
        "Validation accuracy: 88.9%\n",
        "Minibatch loss at step 7000: 16.304571"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 87.5%\n",
        "Validation accuracy: 90.0%\n",
        "Minibatch loss at step 7500: 8.234138"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 93.0%\n",
        "Validation accuracy: 89.8%\n",
        "Minibatch loss at step 8000: 5.141484"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 90.6%\n",
        "Validation accuracy: 88.2%\n",
        "Minibatch loss at step 8500: 8.303648"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.1%\n",
        "Validation accuracy: 89.0%\n",
        "Minibatch loss at step 9000: 7.770896"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 90.6%\n",
        "Validation accuracy: 88.2%\n",
        "Minibatch loss at step 9500: 11.232407"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 87.5%\n",
        "Validation accuracy: 88.9%\n",
        "Minibatch loss at step 10000: 10.975413"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 88.3%\n",
        "Validation accuracy: 87.2%\n",
        "Minibatch loss at step 10500: 5.008749"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 90.6%\n",
        "Validation accuracy: 87.9%\n",
        "Minibatch loss at step 11000: 7.628341"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 90.6%\n",
        "Validation accuracy: 89.3%\n",
        "Minibatch loss at step 11500: 6.775382"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.1%\n",
        "Validation accuracy: 89.3%\n",
        "Minibatch loss at step 12000: 5.280722"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 92.2%\n",
        "Validation accuracy: 88.9%\n",
        "Minibatch loss at step 12500: 8.310295"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.8%\n",
        "Validation accuracy: 89.4%\n",
        "Minibatch loss at step 13000: 5.459477"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.8%\n",
        "Validation accuracy: 87.3%\n",
        "Minibatch loss at step 13500: 9.031740"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 87.5%\n",
        "Validation accuracy: 87.0%\n",
        "Minibatch loss at step 14000: 2.820737"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 93.8%\n",
        "Validation accuracy: 89.3%\n",
        "Minibatch loss at step 14500: 9.421049"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 86.7%\n",
        "Validation accuracy: 88.1%\n",
        "Minibatch loss at step 15000: 7.848868"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 93.0%\n",
        "Validation accuracy: 86.6%\n",
        "Minibatch loss at step 15500: 2.394628"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 92.2%\n",
        "Validation accuracy: 88.2%\n",
        "Minibatch loss at step 16000: 4.095793"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 93.0%\n",
        "Validation accuracy: 88.6%\n",
        "Minibatch loss at step 16500: 4.589471"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 91.4%\n",
        "Validation accuracy: 89.7%\n",
        "Minibatch loss at step 17000: 3.382782"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 91.4%\n",
        "Validation accuracy: 87.9%\n",
        "Minibatch loss at step 17500: 4.678219"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.8%\n",
        "Validation accuracy: 89.1%\n",
        "Minibatch loss at step 18000: 8.115050"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 88.3%\n",
        "Validation accuracy: 88.4%\n",
        "Minibatch loss at step 18500: 6.516118"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 88.3%\n",
        "Validation accuracy: 87.0%\n",
        "Minibatch loss at step 19000: 4.622815"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 92.2%\n",
        "Validation accuracy: 89.1%\n",
        "Minibatch loss at step 19500: 2.994984"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 89.1%\n",
        "Validation accuracy: 87.9%\n",
        "Minibatch loss at step 20000: 4.955485"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Minibatch accuracy: 90.6%\n",
        "Validation accuracy: 88.7%\n",
        "Test accuracy: 89.0%\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}